{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ROOT_DIR = os.getcwd()\n",
    "PRETRAINED_MODEL_DIR = os.path.join(PROJECT_ROOT_DIR, \"models\", \"pretrained\")\n",
    "assert os.path.isdir(PRETRAINED_MODEL_DIR)\n",
    "\n",
    "#   Path to the directory where the pre-trained model will be saved.\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = PRETRAINED_MODEL_DIR\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = PRETRAINED_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(PROJECT_ROOT_DIR, \"results\")\n",
    "LOG_DIR = os.path.join(PROJECT_ROOT_DIR, \"logs\")\n",
    "\n",
    "assert os.path.isdir(RESULTS_DIR) and os.path.isdir(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1846b084dab1451ba5d0203dc6072127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "from transformers import MAMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9158830a145643d2bb5e1f95c2f7b5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in H:\\cs544\\DebaterAI\\DebaterAI\\src\\models\\pretrained. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3be7c9ccd148439bc37417c1f51955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf3260e67b44c748b3b3dc677b7e3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af0947e4ca04611930bb59212b99540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", padding_side=\"right\")\n",
    "baseGPT2 = GPT2Model.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAPTER_NAME = \"mam_adpater\"\n",
    "ADAPTER_CONFIG = MAMConfig()\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "SEQUENCE_EMEBDDING_SIZE = 1024\n",
    "CNN_WINDOW_SIZE = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceEncoderBlock(nn.Module):\n",
    "    '''Sequence encoder block\n",
    "\n",
    "    params: \n",
    "        max_sequence_length: Maximum sequence length\n",
    "        adapter_name: Adapter used for fine-tuning pre-trained encoder\n",
    "        adapter_config: Adapter config\n",
    "        cnn_output_channels: Number of output channels of the CNN(=dimension of the sequence embedding)\n",
    "        cnn_window_size: Window size of the CNN\n",
    "    '''\n",
    "    def __init__(\n",
    "            self, \n",
    "            max_sequence_length,\n",
    "            adapter_name,\n",
    "            adapter_config,\n",
    "            cnn_output_channels,\n",
    "            cnn_window_size\n",
    "        ):\n",
    "        super(SequenceEncoderBlock, self).__init__()\n",
    "\n",
    "        #   Pre-trained GPT-2 model\n",
    "        self.gpt2 = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "        #   Freeze GPT-2 pre-trained parameters\n",
    "        for param in self.gpt2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        #   Add adapter to GPT-2\n",
    "        self.gpt2.add_adapter(adapter_name, config=adapter_config)\n",
    "        self.gpt2.set_active_adapters(adapter_name)\n",
    "\n",
    "        #   CNN layer\n",
    "        self.cnn = nn.Conv1d(\n",
    "            in_channels=self.gpt2.config.hidden_size * 2,\n",
    "            out_channels=cnn_output_channels,\n",
    "            kernel_size=cnn_window_size,\n",
    "            padding=int(cnn_window_size / 2)\n",
    "        )\n",
    "\n",
    "        #   Max pooling layer\n",
    "        self.max_pooling = nn.MaxPool1d(kernel_size=max_sequence_length)\n",
    "\n",
    "        #   Batch normalization layers\n",
    "        self.word_embedding_bn = nn.BatchNorm1d(num_features=self.gpt2.config.hidden_size)\n",
    "        self.encoder_bn = nn.BatchNorm1d(num_features=self.gpt2.config.hidden_size)\n",
    "        self.pooling_bn = nn.BatchNorm1d(cnn_output_channels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        '''Forward propagation\n",
    "\n",
    "        params:\n",
    "            input_ids: Tensor of shape (B, L) containing the input token IDs\n",
    "            attention_mask: Tensor of shape (B, L) containing the attention mask\n",
    "        '''\n",
    "        #   Dimension notations:\n",
    "        #   B: batch size\n",
    "        #   L: sequence length\n",
    "        #   H: hidden size\n",
    "        #   C: number of output channels of the CNN (also the dimension of the sequence embedding)\n",
    "\n",
    "        #   Get word embeddings and last hidden states from GPT-2\n",
    "        outputs = self.gpt2(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "\n",
    "        word_embeddings = outputs.hidden_states[0]\n",
    "        #   Dimension: (B, L, H)\n",
    "        encoder_hidden_states = outputs.last_hidden_state\n",
    "        #   Dimension: (B, L, H)\n",
    "\n",
    "        #   Batch normalization\n",
    "        bn_word_embeddings = self.word_embedding_bn(\n",
    "            word_embeddings.permute(0, 2, 1)\n",
    "        ).permute(0, 2, 1)\n",
    "        bn_encoder_hidden_states = self.encoder_bn(\n",
    "            encoder_hidden_states.permute(0, 2, 1)\n",
    "        ).permute(0, 2, 1)\n",
    "\n",
    "        #   Concatenate word embeddings and encoder hidden states\n",
    "        concat_embeddings = torch.cat((bn_word_embeddings, bn_encoder_hidden_states), dim=-1)\n",
    "        #   Dimension: (B, L, H * 2)\n",
    "\n",
    "        #   Apply attention mask to the concatenated sequence representation\n",
    "        #   The attetion mask is expanded to dimension (B, L, H * 2), \n",
    "        #   matching the dimension of the concatenated sequence representation.\n",
    "        #   The concatenated sequence representation is multiplied element-wise with the attention mask\n",
    "        #   to zero out the padded positions.\n",
    "        masked_concat_embeddings = concat_embeddings * \\\n",
    "            attention_mask.unsqueeze(-1).expand(concat_embeddings.shape)\n",
    "        \n",
    "        #   Apply CNN layer\n",
    "        cnn_out = self.cnn(masked_concat_embeddings.permute(0, 2, 1))\n",
    "        #   Dimension: (B, C, L)\n",
    "\n",
    "        #   Apply max pooling layer\n",
    "        pooled_output = self.max_pooling(cnn_out)\n",
    "        #   Dimension: (B, C, 1)\n",
    "\n",
    "        #   Apply batch normalization\n",
    "        #   This is the final sequence embedding\n",
    "        sequence_embedding = self.pooling_bn(pooled_output.squeeze(-1))\n",
    "        #   Dimension: (B, C)\n",
    "\n",
    "        return sequence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyEncoderModel = SequenceEncoderBlock(\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    adapter_name=ADAPTER_NAME,\n",
    "    adapter_config=ADAPTER_CONFIG,\n",
    "    cnn_output_channels=SEQUENCE_EMEBDDING_SIZE,\n",
    "    cnn_window_size=CNN_WINDOW_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sequence = \"This is a sample sequence for testing the sequence encoder block. It contains multiple sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   There is no default padding token in the GPT-2 tokenizer, \n",
    "#   it is set to the end-of-sequence token instead.\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sequence = tokenizer(\n",
    "    sample_sequence,\n",
    "    padding=\"max_length\",\n",
    "    max_length=MAX_SEQUENCE_LENGTH,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "sample_input_ids = tokenized_sequence[\"input_ids\"].to(DEVICE)\n",
    "sample_attention_mask = tokenized_sequence[\"attention_mask\"].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyEncoderModel.to(DEVICE)\n",
    "MyEncoderModel.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_result = MyEncoderModel(sample_input_ids, sample_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.9514e-01, -6.3662e-03,  1.5514e+00,  ...,  5.4536e+00,\n",
      "          3.0592e+00,  6.4222e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(encoded_result[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
