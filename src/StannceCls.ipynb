{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ROOT_DIR = os.getcwd()\n",
    "PRETRAINED_MODEL_DIR = os.path.join(PROJECT_ROOT_DIR, \"models\", \"pretrained\")\n",
    "assert os.path.isdir(PRETRAINED_MODEL_DIR)\n",
    "\n",
    "#   Path to the directory where the pre-trained model will be saved.\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = PRETRAINED_MODEL_DIR\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = PRETRAINED_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join(PROJECT_ROOT_DIR, \"results\")\n",
    "LOG_DIR = os.path.join(PROJECT_ROOT_DIR, \"logs\")\n",
    "\n",
    "assert os.path.isdir(RESULTS_DIR) and os.path.isdir(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "from transformers import MAMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Initialize the GPT-2 tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", padding_side=\"right\")\n",
    "\n",
    "#   There is no default padding token in the GPT-2 tokenizer, \n",
    "#   it is set to the end-of-sequence token instead.\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Hyperparameters for SequenceEncoder block.\n",
    "ADAPTER_NAME = \"mam_adpater\"\n",
    "ADAPTER_CONFIG = MAMConfig()\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "SEQUENCE_EMEBDDING_SIZE = 1024\n",
    "CNN_WINDOW_SIZE = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceEncoderBlock(nn.Module):\n",
    "    '''Sequence encoder block\n",
    "\n",
    "    params: \n",
    "        max_sequence_length: Maximum sequence length\n",
    "        adapter_name: Adapter used for fine-tuning pre-trained encoder\n",
    "        adapter_config: Adapter config\n",
    "        cnn_output_channels: Number of output channels of the CNN(=dimension of the sequence embedding)\n",
    "        cnn_window_size: Window size of the CNN\n",
    "    '''\n",
    "    def __init__(\n",
    "            self, \n",
    "            max_sequence_length,\n",
    "            adapter_name,\n",
    "            adapter_config,\n",
    "            cnn_output_channels,\n",
    "            cnn_window_size\n",
    "        ):\n",
    "        super(SequenceEncoderBlock, self).__init__()\n",
    "\n",
    "        #   Pre-trained GPT-2 model\n",
    "        self.gpt2 = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "        #   Freeze GPT-2 pre-trained parameters\n",
    "        for param in self.gpt2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        #   Add adapter to GPT-2\n",
    "        self.gpt2.add_adapter(adapter_name, config=adapter_config)\n",
    "        self.gpt2.set_active_adapters(adapter_name)\n",
    "\n",
    "        #   CNN layer\n",
    "        self.cnn = nn.Conv1d(\n",
    "            in_channels=self.gpt2.config.hidden_size * 2,\n",
    "            out_channels=cnn_output_channels,\n",
    "            kernel_size=cnn_window_size,\n",
    "            padding=int(cnn_window_size / 2)\n",
    "        )\n",
    "\n",
    "        #   Max pooling layer\n",
    "        self.max_pooling = nn.MaxPool1d(kernel_size=max_sequence_length)\n",
    "\n",
    "        #   Batch normalization layers\n",
    "        self.word_embedding_bn = nn.BatchNorm1d(num_features=self.gpt2.config.hidden_size)\n",
    "        self.encoder_bn = nn.BatchNorm1d(num_features=self.gpt2.config.hidden_size)\n",
    "        self.pooling_bn = nn.BatchNorm1d(cnn_output_channels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        '''Forward propagation\n",
    "\n",
    "        params:\n",
    "            input_ids: Tensor of shape (B, L) containing the input token IDs\n",
    "            attention_mask: Tensor of shape (B, L) containing the attention mask\n",
    "        '''\n",
    "        #   Dimension notations:\n",
    "        #   B: batch size\n",
    "        #   L: sequence length\n",
    "        #   H: hidden size\n",
    "        #   C: number of output channels of the CNN (also the dimension of the sequence embedding)\n",
    "\n",
    "        #   Get word embeddings and last hidden states from GPT-2\n",
    "        outputs = self.gpt2(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "\n",
    "        word_embeddings = outputs.hidden_states[0]\n",
    "        #   Dimension: (B, L, H)\n",
    "        encoder_hidden_states = outputs.last_hidden_state\n",
    "        #   Dimension: (B, L, H)\n",
    "\n",
    "        #   Batch normalization\n",
    "        bn_word_embeddings = self.word_embedding_bn(\n",
    "            word_embeddings.permute(0, 2, 1)\n",
    "        ).permute(0, 2, 1)\n",
    "        bn_encoder_hidden_states = self.encoder_bn(\n",
    "            encoder_hidden_states.permute(0, 2, 1)\n",
    "        ).permute(0, 2, 1)\n",
    "\n",
    "        #   Concatenate word embeddings and encoder hidden states\n",
    "        concat_embeddings = torch.cat((bn_word_embeddings, bn_encoder_hidden_states), dim=-1)\n",
    "        #   Dimension: (B, L, H * 2)\n",
    "\n",
    "        #   Apply attention mask to the concatenated sequence representation\n",
    "        #   The attetion mask is expanded to dimension (B, L, H * 2), \n",
    "        #   matching the dimension of the concatenated sequence representation.\n",
    "        #   The concatenated sequence representation is multiplied element-wise with the attention mask\n",
    "        #   to zero out the padded positions.\n",
    "        masked_concat_embeddings = concat_embeddings * \\\n",
    "            attention_mask.unsqueeze(-1).expand(concat_embeddings.shape)\n",
    "        \n",
    "        #   Apply CNN layer\n",
    "        cnn_out = self.cnn(masked_concat_embeddings.permute(0, 2, 1))\n",
    "        #   Dimension: (B, C, L)\n",
    "\n",
    "        #   Apply max pooling layer\n",
    "        pooled_output = self.max_pooling(cnn_out)\n",
    "        #   Dimension: (B, C, 1)\n",
    "\n",
    "        #   Apply batch normalization\n",
    "        #   This is the final sequence embedding\n",
    "        sequence_embedding = self.pooling_bn(pooled_output.squeeze(-1))\n",
    "        #   Dimension: (B, C)\n",
    "\n",
    "        return sequence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Hyperparameters for the combined classifier.\n",
    "FF_HIDDEN_SIZE = 4 * SEQUENCE_EMEBDDING_SIZE\n",
    "NUM_CLASSES = 3                                 #   0: Neutral, 1: Agree, 2: Disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanceClassifier(nn.Module):\n",
    "    '''Stance classifier\n",
    "\n",
    "    params:\n",
    "        parent_encoder: Sequence encoder block for parent comments\n",
    "        child_encoder: Sequence encoder block for child comments\n",
    "        context_encoder: Sequence encoder block for comment context\n",
    "        sequence_embedding_size: Dimension of the sequence embedding\n",
    "        ff_hidden_size: Hidden size of the feed-forward layer\n",
    "        num_classes: Number of classes\n",
    "    '''\n",
    "    def __init__(\n",
    "            self, \n",
    "            parent_encoder: SequenceEncoderBlock,\n",
    "            child_encoder: SequenceEncoderBlock,\n",
    "            context_encoder: SequenceEncoderBlock,\n",
    "            loss_fn,\n",
    "            sequence_embedding_size,\n",
    "            ff_hidden_size,\n",
    "            num_classes\n",
    "        ):\n",
    "        super(StanceClassifier, self).__init__()\n",
    "\n",
    "        self.parent_encoder = parent_encoder\n",
    "        self.child_encoder = child_encoder\n",
    "        self.context_encoder = context_encoder\n",
    "\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        #   Feed-forward layer\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(sequence_embedding_size * 2, ff_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_size, sequence_embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(sequence_embedding_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_masks, labels=None):\n",
    "        '''Forward propagation\n",
    "\n",
    "        params:\n",
    "            input_ids: list tensors of shape (B, L) containing the input token IDs\n",
    "            attention_masks: list tensors of shape (B, L) containing the attention masks\n",
    "            labels: Tensor of shape (B,) containing the labels\n",
    "        '''\n",
    "        #   Dimension notations:\n",
    "        #   B: batch size\n",
    "        #   S: dimension of the sequence embedding\n",
    "        #   C: number of classes\n",
    "\n",
    "        parent_embeddings = self.parent_encoder(\n",
    "            input_ids=input_ids[0],\n",
    "            attention_mask=attention_masks[0]\n",
    "        )\n",
    "        child_embeddings = self.child_encoder(\n",
    "            input_ids=input_ids[1],\n",
    "            attention_mask=attention_masks[1]\n",
    "        )\n",
    "        context_embeddings = self.context_encoder(\n",
    "            input_ids=input_ids[2],\n",
    "            attention_mask=attention_masks[2]\n",
    "        )\n",
    "        #   Dimension: 3 * (B, S)\n",
    "\n",
    "        #   Create the combined sequence embedding for classification\n",
    "        combined_embeddings = torch.cat(\n",
    "            (parent_embeddings + context_embeddings, child_embeddings + context_embeddings),\n",
    "            dim=-1\n",
    "        )\n",
    "        #   Dimension: (B, S * 2)\n",
    "\n",
    "        #   Feed-forward layer\n",
    "        logits = self.ff(combined_embeddings)\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(loss=loss, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Collate function for the combined classifier\n",
    "class CustomDataCollator:\n",
    "    def __init__(self, tokenizer: GPT2Tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        #   Dimension notations:\n",
    "        #   B: batch size\n",
    "        #   L: sequence length\n",
    "\n",
    "        parent_comment = [item['parent_comment'] for item in batch]\n",
    "        child_comment = [item['child_comment'] for item in batch]\n",
    "        context = [item['context'] for item in batch]\n",
    "        labels = [item['label'] for item in batch]\n",
    "\n",
    "        #   Tokenize the input sequences\n",
    "        parent_tokenized = self.tokenizer(\n",
    "            parent_comment,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_SEQUENCE_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        child_tokenized = self.tokenizer(\n",
    "            child_comment,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_SEQUENCE_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        context_tokenized = self.tokenizer(\n",
    "            context,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_SEQUENCE_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        input_ids = [\n",
    "            parent_tokenized['input_ids'], \n",
    "            child_tokenized['input_ids'], \n",
    "            context_tokenized['input_ids']\n",
    "        ]\n",
    "        attention_masks = [\n",
    "            parent_tokenized['attention_mask'],\n",
    "            child_tokenized['attention_mask'],\n",
    "            context_tokenized['attention_mask']\n",
    "        ]\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_masks\": attention_masks, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_compute_metrics(eval_pred: EvalPrediction) -> dict:\n",
    "    '''Compute metrics for the combined classifier\n",
    "\n",
    "    params:\n",
    "        eval_pred: EvalPrediction object\n",
    "    '''\n",
    "    #   Dimension notations:\n",
    "    #   B: batch size\n",
    "    #   C: number of classes\n",
    "\n",
    "    #   Dimension of prediction logits: (B, C)\n",
    "\n",
    "    #   Convert logits to predictions\n",
    "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
    "    #   Dimension: (B,)\n",
    "\n",
    "    #   Compute precision, recall, and F1 score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        eval_pred.label_ids, preds, average=\"weighted\"\n",
    "    )\n",
    "\n",
    "    #   Compute confusion matrix\n",
    "    cm = confusion_matrix(eval_pred.label_ids, preds)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": cm.diagonal() / cm.sum()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model: nn.Module, inputs: dict, return_outputs=False):\n",
    "        #   Dimension notations:\n",
    "        #   B: batch size\n",
    "        #   L: sequence length\n",
    "        #   C: number of classes\n",
    "\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        #   Dimension: 3 * (B, L)\n",
    "        attention_masks = inputs[\"attention_masks\"]\n",
    "        #   Dimension: 3 * (B, L)\n",
    "        labels = inputs[\"labels\"]\n",
    "        #   Dimension: (B,)\n",
    "\n",
    "        outputs = model(input_ids, attention_masks, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "\n",
    "        return (loss, logits) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "#   Dataset class for the combined classifier\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, items: list):\n",
    "        self.items = items\n",
    "\n",
    "    def __len__(self):\n",
    "        self.items.__len__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #   TODO: this part need to be implemented based on actual dataset.\n",
    "        #   The inidividual item returned by __getitem__ should be a dictionary\n",
    "        #   containing the following keys:\n",
    "        #   - parent_comment: string\n",
    "        #   - child_comment: string\n",
    "        #   - context: string\n",
    "        #   - label: int (0: Neutral, 1: Agree, 2: Disagree)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Training arguments (need to be changed based on actual performance)\n",
    "TRAINING_EPOCHS = 10\n",
    "BACTH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeqEncoder1 = SequenceEncoderBlock(\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    adapter_name=ADAPTER_NAME,\n",
    "    adapter_config=ADAPTER_CONFIG,\n",
    "    cnn_output_channels=SEQUENCE_EMEBDDING_SIZE,\n",
    "    cnn_window_size=CNN_WINDOW_SIZE\n",
    ")\n",
    "\n",
    "SeqEncoder2 = SequenceEncoderBlock(\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    adapter_name=ADAPTER_NAME,\n",
    "    adapter_config=ADAPTER_CONFIG,\n",
    "    cnn_output_channels=SEQUENCE_EMEBDDING_SIZE,\n",
    "    cnn_window_size=CNN_WINDOW_SIZE\n",
    ")\n",
    "\n",
    "SeqEncoder3 = SequenceEncoderBlock(\n",
    "    max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    adapter_name=ADAPTER_NAME,\n",
    "    adapter_config=ADAPTER_CONFIG,\n",
    "    cnn_output_channels=SEQUENCE_EMEBDDING_SIZE,\n",
    "    cnn_window_size=CNN_WINDOW_SIZE\n",
    ")\n",
    "\n",
    "CLSModel = StanceClassifier(\n",
    "    parent_encoder=SeqEncoder1,\n",
    "    child_encoder=SeqEncoder2,\n",
    "    context_encoder=SeqEncoder3,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    sequence_embedding_size=SEQUENCE_EMEBDDING_SIZE,\n",
    "    ff_hidden_size=FF_HIDDEN_SIZE,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "#   Optimizer and LR scheduler may need to be changed based on actual performance\n",
    "#   This is the default setting from the Trainer implementation\n",
    "optimizer = AdamW(CLSModel.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = LambdaLR(optimizer, lambda epoch: 1 / (epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyCollator = CustomDataCollator(tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=RESULTS_DIR,\n",
    "    logging_dir=LOG_DIR,\n",
    "    num_train_epochs=TRAINING_EPOCHS,\n",
    "    per_device_train_batch_size=BACTH_SIZE,\n",
    "    per_device_eval_batch_size=BACTH_SIZE,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=CLSModel,\n",
    "    args=training_args,\n",
    "    train_dataset=None,     #   Change this to the training dataset\n",
    "    eval_dataset=None,      #   Change this to the evaluation dataset\n",
    "    data_collator=MyCollator,\n",
    "    optimizers=(optimizer, lr_scheduler),\n",
    "    compute_metrics=custom_compute_metrics\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
